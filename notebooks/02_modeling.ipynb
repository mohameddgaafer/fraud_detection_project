{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5.2 Class Imbalance Strategy — Data Preparation\n",
        "\n",
        "In this section, we prepare the processed provider-level dataset for handling\n",
        "class imbalance. We:\n",
        "\n",
        "- Load the `provider_features.csv` file generated in Notebook 01.\n",
        "- Encode the target label (`PotentialFraud`) as 0/1.\n",
        "- Handle any remaining missing values.\n",
        "- Split the data into stratified train and test sets, preserving the fraud ratio.\n",
        "\n",
        "These steps prepare the data so we can correctly apply a class imbalance strategy (SMOTE).\n"
      ],
      "metadata": {
        "id": "E4nq0EUrq4Q4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQA2xwBpLq2L",
        "outputId": "5942db25-c66e-483b-d425-16a92b0b53b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training class distribution (y_train):\n",
            "PotentialFraud\n",
            "0    0.906581\n",
            "1    0.093419\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# 1. Load data and basic preprocessing (for class imbalance handling)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load provider-level features from Notebook 01\n",
        "df = pd.read_csv(\"provider_features.csv\")\n",
        "\n",
        "# Encode target label: No -> 0, Yes -> 1\n",
        "df[\"PotentialFraud\"] = df[\"PotentialFraud\"].map({\"No\": 0, \"Yes\": 1})\n",
        "\n",
        "# Make sure there are no missing values in the modeling features\n",
        "df = df.fillna(0)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop([\"Provider\", \"PotentialFraud\"], axis=1)\n",
        "y = df[\"PotentialFraud\"]\n",
        "\n",
        "# Stratified train/test split to preserve fraud ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# Optional: check class distribution in training set\n",
        "print(\"Training class distribution (y_train):\")\n",
        "print(y_train.value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5.2 Class Imbalance Strategy — SMOTE Oversampling\n",
        "\n",
        "The dataset is highly imbalanced (fraudulent providers are a small minority).\n",
        "To address this, we use **SMOTE (Synthetic Minority Oversampling Technique)** on\n",
        "the training data only.\n",
        "\n",
        "This step directly implements the class imbalance strategy required in section 1.5.2.\n"
      ],
      "metadata": {
        "id": "JbzjQQtTh-tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Apply SMOTE to balance the training data\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Class distribution BEFORE SMOTE:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "print(\"\\nClass distribution AFTER SMOTE:\")\n",
        "print(y_train_res.value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HbzJBxmMK2C",
        "outputId": "395f0b6d-d832-4546-9e92-1905eb9bcfff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution BEFORE SMOTE:\n",
            "PotentialFraud\n",
            "0    3678\n",
            "1     379\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class distribution AFTER SMOTE:\n",
            "PotentialFraud\n",
            "0    3678\n",
            "1    3678\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5.3 Algorithm Selection — Training Selected Models\n",
        "\n",
        "We now train two different algorithms on the balanced training data:\n",
        "\n",
        "- **Logistic Regression**: interpretable baseline model.\n",
        "- **Random Forest**: more powerful tree-based model, robust to mixed features.\n",
        "\n",
        "This satisfies section 1.5.3 by evaluating relevant algorithms and preparing to\n",
        "select a primary model.\n"
      ],
      "metadata": {
        "id": "jl-35BFwiYM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Train Logistic Regression and Random Forest on the balanced data\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Logistic Regression (interpretable baseline)\n",
        "log_reg = LogisticRegression(\n",
        "    max_iter=2000,\n",
        "    class_weight=\"balanced\"\n",
        ")\n",
        "log_reg.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Random Forest (primary model candidate)\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    random_state=42,\n",
        "    class_weight=\"balanced_subsample\"\n",
        ")\n",
        "rf.fit(X_train_res, y_train_res)\n",
        "\n",
        "print(\"Models trained successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UNg11j0MsoU",
        "outputId": "e7b3656a-a337-4a91-8fa2-a77ed8a86e85"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5.4 Comparison Models — Evaluation & Metrics\n",
        "\n",
        "Here we compare Logistic Regression and Random Forest using metrics that are\n",
        "appropriate for imbalanced classification:\n",
        "\n",
        "- Precision\n",
        "- Recall\n",
        "- F1-score\n",
        "- ROC-AUC\n",
        "\n",
        "This fulfills section 1.5.4 by using standardized metrics to compare models.\n",
        "We will later create curves and deeper error analysis in Notebook 03.\n"
      ],
      "metadata": {
        "id": "fjmrC_oVrSCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Evaluate and compare models on the (original) test set\n",
        "\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# Random Forest predictions\n",
        "rf_preds = rf.predict(X_test)\n",
        "rf_probs = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"=== Random Forest ===\")\n",
        "print(classification_report(y_test, rf_preds))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, rf_probs))\n",
        "\n",
        "# Logistic Regression predictions\n",
        "log_preds = log_reg.predict(X_test)\n",
        "log_probs = log_reg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\n=== Logistic Regression ===\")\n",
        "print(classification_report(y_test, log_preds))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, log_probs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgA6W5R0rUxA",
        "outputId": "0126fb0a-6a4a-4cb3-a652-15309aef63b7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Random Forest ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.93      0.95      1226\n",
            "           1       0.51      0.71      0.60       127\n",
            "\n",
            "    accuracy                           0.91      1353\n",
            "   macro avg       0.74      0.82      0.77      1353\n",
            "weighted avg       0.93      0.91      0.92      1353\n",
            "\n",
            "ROC-AUC: 0.9204377593094503\n",
            "\n",
            "=== Logistic Regression ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.87      0.92      1226\n",
            "           1       0.40      0.85      0.54       127\n",
            "\n",
            "    accuracy                           0.86      1353\n",
            "   macro avg       0.69      0.86      0.73      1353\n",
            "weighted avg       0.93      0.86      0.88      1353\n",
            "\n",
            "ROC-AUC: 0.9208295333393276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Save predictions and probabilities to CSV\n",
        "\n",
        "# Get the Provider IDs for the test set\n",
        "providers_test = df.loc[X_test.index, \"Provider\"]\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    \"Provider\": providers_test,\n",
        "    \"ActualFraud\": y_test.values,\n",
        "    \"PredictedFraud_RF\": rf_preds,\n",
        "    \"FraudProbability_RF\": rf_probs,\n",
        "    \"PredictedFraud_LR\": log_preds,\n",
        "    \"FraudProbability_LR\": log_probs,\n",
        "})\n",
        "\n",
        "results.to_csv(\"model_predictions.csv\", index=False)\n",
        "print(\"Saved predictions to model_predictions.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d7EeVIerXmr",
        "outputId": "64be7dd7-dfc2-456b-b036-4d8543892f4e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved predictions to model_predictions.csv\n"
          ]
        }
      ]
    }
  ]
}